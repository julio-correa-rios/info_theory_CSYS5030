{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and variance and extending JIDT code\n",
    "\n",
    "This activity illustrates bias and variance of MI estimates, and gets you started extending the code generated by the JIDT AutoAnalyser.\n",
    "\n",
    "1. Start by generating the code again for the demonstration of the Discrete MI on slide 20 of Session 3 Introduction to JIDT.\n",
    "<br>\n",
    "\n",
    "2. Open the generated Python code in the file demos/AutoAnalyser/GeneratedCalculator.py, or copy and past the code from the Python tab into either a new .py file or a Jupyter notebook (can be placed anywhere).\n",
    "<br>\n",
    "\n",
    "3. Edit step 0 of the code which loads the data in to the source and destination variables:<br>\n",
    "    a. First remove the line where the file is loaded.\n",
    "    <br>\n",
    "    b. Next, change the assignment of the source variable to be an array of 10 random bits: source = np.random.randint(0,2,size=10).<br>\n",
    "\n",
    "    c. Finally, change the assignment of the destination variable to be a copy of the source: destination = source;\n",
    "    Congratulations, you have made your first extension of the automatically generated JIDT code! Now run the code in Python. Start Python (if you're not already editing the .ipynb file after launching your Jupyter notebook), and change the working directory to demos/AutoAnalyer/. Run GeneratedCalculator (or the alternative name of your script) as you run every single file.\n",
    "<br>\n",
    "\n",
    "4. Note the result. Was it the full 1 bit of shared information the we would expect for copied random bits?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jpype import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our python data file readers are a bit of a hack, python users will do better on this:\n",
    "sys.path.append(\"/Users/juliocorrearios/Dropbox/MCSX/Semester2/InformationTheory/JIDT/infodynamics-dist-1.5/demos/python\")\n",
    "import readIntsFile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add JIDT jar library to the path\n",
    "jarLocation = \"/Users/juliocorrearios/Dropbox/MCSX/Semester2/InformationTheory/JIDT/infodynamics-dist-1.5/infodynamics.jar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the JVM (add the \"-Xmx\" option with say 1024M if you get crashes due to not enough memory space)\n",
    "startJVM(getDefaultJVMPath(), \"-ea\", \"-Djava.class.path=\" + jarLocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load/prepare the data:\n",
    "dataRaw = readIntsFile.readIntsFile(\"/Users/juliocorrearios/Dropbox/MCSX/Semester2/InformationTheory/JIDT/infodynamics-dist-1.5/demos/data/2coupledDiscreteCols-1.txt\")\n",
    "# As numpy array:\n",
    "data = np.array(dataRaw)\n",
    "source = data[:,0]\n",
    "destination = data[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_Discrete(col_0 -> col_1) = 0.0007 bits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Construct the calculator:\n",
    "calcClass = JPackage(\"infodynamics.measures.discrete\").MutualInformationCalculatorDiscrete\n",
    "calc = calcClass(4, 4, 0)\n",
    "# 2. No other properties to set for discrete calculators.\n",
    "# 3. Initialise the calculator for (re-)use:\n",
    "calc.initialise()\n",
    "# 4. Supply the sample data:\n",
    "calc.addObservations(source, destination)\n",
    "# 5. Compute the estimate:\n",
    "result = calc.computeAverageLocalOfObservations()\n",
    "\n",
    "print(\"MI_Discrete(col_0 -> col_1) = {:.04f} bits\".format(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.\n",
    "\n",
    "5. Run the code several more times and note the results. Are they always the same or do they vary? Why is this?\n",
    "<br>\n",
    "\n",
    "6. Capture the results of running the code several times (say 10 times) into an array and measure the mean and variance of the results. (Hint: in Python, there are different ways to do it, one of the simplest is to append the results in a list, and it should look like this: results.append(<b>yourCalculation</b>)). You would be best to use a for loop to run the code 10 times). Compute the bias as the difference between the mean empirical result and the expected result. It is quite large here because we have computed the empirical results from so few samples (10). In the lecture we noted that MI is typically biased upwards, which referred to situations where variables don't actually share any information; where variables do indeed share information, the MI can be biased downwards as is the case here. Also try to increase the number of samples (e.g. upwards from 10 random bits to 100) and see how the bias and variance change.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "\n",
    "n_iterations = 10\n",
    "results = [] # Append the results in a list\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    source = np.random.randint(0,2,size=10)\n",
    "    destination = source\n",
    "    \n",
    "    calc.initialise()\n",
    "    calc.addObservations(source, destination)\n",
    "    results.append(calc.computeAverageLocalOfObservations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9709505944546686,\n",
       " 0.9709505944546686,\n",
       " 0.9709505944546686,\n",
       " 0.9709505944546686,\n",
       " 0.7219280948873621,\n",
       " 0.9709505944546686,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9709505944546686]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
